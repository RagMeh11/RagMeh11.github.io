---
---


%%% Journals

@article{melba:2022:029:nichyporuk,
    abbr={MELBA},
    bibtex_show={true},
    title={Rethinking Generalization: The Impact of Annotation Style on Medical Image Segmentation},
    author={Nichyporuk, Brennan and Cardinell, Jillian and Szeto, Justin and Mehta, Raghav and Falet, Jean-Pierre and Arnold, Douglas L. and Tsaftaris, Sotirios A. and Arbel, Tal},
    journal={Machine Learning for Biomedical Imaging},
    volume={1},
    issue={December 2022 issue},
    year={2022},
    pages={1--37},
    issn={2766-905X},
    doi={https://doi.org/10.59275/j.melba.2022-2d93},
    html={https://melba-journal.org/2022:029},
    arxiv={arXiv:2210.17398}
}

@article{melba:2022:026:mehta,
    abbr={MELBA},
    bibtex_show={true},
    title={QU-BraTS: MICCAI BraTS 2020 Challenge on Quantifying Uncertainty in Brain Tumor Segmentation – Analysis of Ranking Scores and Benchmarking Results},
    author={Mehta, Raghav and Filos, Angelos and Baid, Ujjwal and Sako, Chiharu and McKinley, Richard and Rebsamen, Michael and Dätwyler, Katrin and Meier, Raphael and Radojewski, Piotr and Murugesan, Gowtham Krishnan and Nalawade, Sahil and Ganesh, Chandan and Wagner, Ben and Yu, Fang F. and Fei, Baowei and Madhuranthakam, Ananth J. and Maldjian, Joseph A. and Daza, Laura and Gómez, Catalina and Arbeláez, Pablo and Dai, Chengliang and Wang, Shuo and Reynaud, Hadrien and Mo, Yuanhan and Angelini, Elsa and Guo, Yike and Bai, Wenjia and Banerjee, Subhashis and Pei, Linmin and AK, Murat and Rosas-González, Sarahi and Zemmoura, Ilyess and Tauber, Clovis and Vu, Minh H. and Nyholm, Tufve and Löfstedt, Tommy and Ballestar, Laura Mora and Vilaplana, Veronica and McHugh, Hugh and Maso Talou, Gonzalo and Wang, Alan and Patel, Jay and Chang, Ken and Hoebel, Katharina and Gidwani, Mishka and Arun, Nishanth and Gupta, Sharut and Aggarwal, Mehak and Singh, Praveer and Gerstner, Elizabeth R. and Kalpathy-Cramer, Jayashree and Boutry, Nicolas and Huard, Alexis and Vidyaratne, Lasitha and Rahman, Md Monibor and Iftekharuddin, Khan M. and Chazalon, Joseph and Puybareau, Elodie and Tochon, Guillaume and Ma, Jun and Cabezas, Mariano and Llado, Xavier and Oliver, Arnau and Valencia, Liliana and Valverde, Sergi and Amian, Mehdi and Soltaninejad, Mohammadreza and Myronenko, Andriy and Hatamizadeh, Ali and Feng, Xue and Dou, Quan and Tustison, Nicholas and Meyer, Craig and Shah, Nisarg A. and Talbar, Sanjay and Weber, Marc-André and Mahajan, Abhishek and Jakab, Andras and Wiest, Roland and Fathallah-Shaykh, Hassan M. and Nazeri, Arash and Milchenko, Mikhail and Marcus, Daniel and Kotrotsou, Aikaterini and Colen, Rivka and Freymann, John and Kirby, Justin and Davatzikos, Christos and Menze, Bjoern and Bakas, Spyridon and Gal, Yarin and Arbel, Tal},
    journal={Machine Learning for Biomedical Imaging},
    volume={1},
    issue={August 2022 issue},
    year={2022},
    pages={1--54},
    issn={2766-905X},
    doi={https://doi.org/10.59275/j.melba.2022-354b},
    html={https://melba-journal.org/2022:026},
    arxiv={arXiv:2112.10074},
    selected={true}
}

@article{mehta2021propagating,
  abbr={TMI},
  bibtex_show={true},
  title={Propagating uncertainty across cascaded medical imaging tasks for improved deep learning inference},
  author={Mehta, Raghav and Christinck, Thomas and Nair, Tanya and Bussy, Aur{\'e}lie and Premasiri, Swapna and Costantino, Manuela and Chakravarthy, M Mallar and Arnold, Douglas L and Gal, Yarin and Arbel, Tal},
  journal={IEEE Transactions on Medical Imaging},
  volume={41},
  number={2},
  pages={360--373},
  year={2021},
  publisher={IEEE},
  doi={https://doi.org/10.1109/TMI.2021.3114097},
  html={https://ieeexplore.ieee.org/document/9541203},
  selected={true}
}

@article{sivaswamy2019construction,
  abbr={NI},
  bibtex_show={true},
  title={Construction of Indian human brain atlas},
  author={Sivaswamy, Jayanthi and Thottupattu, Alphin J and Mehta, Raghav and Sheelakumari, R and Kesavadas, Chandrasekharan and others},
  journal={Neurology India},
  volume={67},
  number={1},
  pages={229},
  year={2019},
  publisher={Medknow Publications},
  doi={https://doi.org/10.4103/0028-3886.253639},
  html={https://pubmed.ncbi.nlm.nih.gov/30860125/},
  selected={true}
}


@article{mehta2017brainsegnet,
  abbr={JMI},
  bibtex_show={true},
  title={BrainSegNet: a convolutional neural network architecture for automated segmentation of human brain structures},
  author={Mehta, Raghav and Majumdar, Aabhas and Sivaswamy, Jayanthi},
  journal={Journal of Medical Imaging},
  volume={4},
  number={2},
  pages={024003--024003},
  year={2017},
  publisher={Society of Photo-Optical Instrumentation Engineers},
  doi={https://doi.org/10.1117/1.JMI.4.2.024003},
  html={https://www.spiedigitallibrary.org/journals/Journal-of-Medical-Imaging/volume-4/issue-2/024003/BrainSegNet--a-convolutional-neural-network-architecture-for-automated-segmentation/10.1117/1.JMI.4.2.024003.short?SSO=1#_=_}
}


%%%% conferences

@inproceedings{shui2023mitigating,
  abbr={MICCAI},
  bibtex_show={true},
  title={Mitigating calibration bias without fixed attribute grouping for improved fairness in medical imaging analysis},
  author={Shui, Changjian and Szeto, Justin and Mehta, Raghav and Arnold, Douglas L and Arbel, Tal},
  booktitle={International Conference on Medical Image Computing and Computer-Assisted Intervention},
  pages={189--198},
  year={2023},
  organization={Springer},
  doi={https://doi.org/10.1007/978-3-031-43898-1_19},
  html={https://link.springer.com/chapter/10.1007/978-3-031-43898-1_19},
  arxiv={arXiv:2307.01738},
  selected={true}
}


@inproceedings{durso2023improving,
  abbr={MICCAI},
  bibtex_show={true},
  title={Improving Image-Based Precision Medicine with Uncertainty-Aware Causal Models},
  author={Durso-Finley, Joshua and Falet, Jean-Pierre and Mehta, Raghav and Arnold, Douglas L and Pawlowski, Nick and Arbel, Tal},
  booktitle={International Conference on Medical Image Computing and Computer-Assisted Intervention},
  pages={72--481},
  year={2023},
  organization={Springer},
  html={https://link.springer.com/chapter/10.1007/978-3-031-43904-9_46},
  doi={https://doi.org/10.1007/978-3-031-43904-9_46},
  arxiv={arXiv:2305.03829},
  selected={true}
}


@inproceedings{mehta2023evaluating,
  abbr={MIDL},
  bibtex_show={true},
  title={Evaluating the Fairness of Deep Learning Uncertainty Estimates in Medical Image Analysis},
  author={Mehta, Raghav and Shui, Changjian and Arbel, Tal},
  booktitle={Medical Imaging with Deep Learning},
  pages={000-000},
  year={2023},
  organization={PMLR},
  html={https://arxiv.org/abs/2303.03242},
  arxiv={arXiv:2303.03242},
  poster={MIDL_2023_Fairness_Uncertainty.pdf},
  selected={true}
}


@inproceedings{vadacchino2021had,
  abbr={MIDL},
  bibtex_show={true},
  title={Had-net: A hierarchical adversarial knowledge distillation network for improved enhanced tumour segmentation without post-contrast images},
  author={Vadacchino, Saverio and Mehta, Raghav and Sepahvand, Nazanin Mohammadi and Nichyporuk, Brennan and Clark, James J and Arbel, Tal},
  booktitle={Medical Imaging with Deep Learning},
  pages={787--801},
  year={2021},
  organization={PMLR},
  html={https://proceedings.mlr.press/v143/vadacchino21a.html},
  arxiv={arXiv:2103.16617},
  slides={HAD_Net_Presentation_MIDL_Short.pdf}
}

@article{mehta2020uncertainty,
  abbr={MIDL},
  bibtex_show={true},
  title={Uncertainty evaluation metric for brain tumour segmentation},
  author={Mehta, Raghav and Filos, Angelos and Gal, Yarin and Arbel, Tal},
  journal={Medical Imaging with Deep Learning Short Papers},
  html={https://arxiv.org/abs/2005.14262},
  arxiv={arXiv:2005.14262},
  year={2020},
  slides={Mehta20-slides.pdf}
}

@inproceedings{mehta2017m,
  abbr={ISBI},
  bibtex_show={true},
  title={M-net: A convolutional neural network for deep brain structure segmentation},
  author={Mehta, Raghav and Sivaswamy, Jayanthi},
  booktitle={2017 IEEE 14th International Symposium on Biomedical Imaging (ISBI)},
  pages={437--440},
  year={2017},
  organization={IEEE},
  html={https://ieeexplore.ieee.org/abstract/document/7950555},
  doi={https://doi.org/10.1109/ISBI.2017.7950555},
  slides={ISBI_2017_Mnet.pdf}
}

@inproceedings{mehta2016hybrid,
  abbr={ISBI},
  bibtex_show={true},
  title={A hybrid approach to tissue-based intensity standardization of brain MRI images},
  author={Mehta, Raghav and Sivaswamy, Jayanthi},
  booktitle={2016 IEEE 13th International Symposium on Biomedical Imaging (ISBI)},
  pages={95--98},
  year={2016},
  organization={IEEE},
  html={https://ieeexplore.ieee.org/abstract/document/7493219},
  doi={https://doi.org/10.1109/ISBI.2016.7493219},
  poster={ISBI_IS_Poster_Draft_print.pdf}
}


%%%%% workshops

@inproceedings{kumar2023debiasing,
  abbr={FAIMI},
  bibtex_show={true},
  title={Debiasing Counterfactuals in the Presence of Spurious Correlations},
  author={Kumar, Amar and Fathi, Nima and Mehta, Raghav and Nichyporuk, Brennan and Falet, Jean-Pierre R and Tsaftaris, Sotirios and Arbel, Tal},
  booktitle={MICCAI Workshop on Fairness of AI in Medical Imaging (FAIMI)},
  pages={276--286},
  year={2023},
  organization={Springer},
  html={https://link.springer.com/chapter/10.1007/978-3-031-45249-9_27},
  doi={https://doi.org/10.1007/978-3-031-45249-9_27},
  slides={FAIMI_MICCAI2023_Amar.pdf},
  poster={FAIMI_2023_Poster.pdf}
}

@InProceedings{albiero2023confusing,
    abbr={OODCV},
    bibtex_show={true},
    author={Albiero, V{\'\i}tor and Mehta, Raghav and Evtimov, Ivan and Bell, Samuel and Sagun, Levent and Markosyan, Aram},
    title={Confusing Large Models by Confusing Small Models},
    booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV) Workshops},
    year={2023},
    pages={4304-4312},
    html={https://openaccess.thecvf.com/content/ICCV2023W/OODCV/html/Albiero_Confusing_Large_Models_by_Confusing_Small_Models_ICCVW_2023_paper.html}
}


@InProceedings{mehta2022you,
    abbr={RCV},
    bibtex_show={true},
    title={You only need a good embeddings extractor to fix spurious correlations},
    author={Mehta, Raghav and Albiero, V{\'\i}tor and Chen, Li and Evtimov, Ivan and Glaser, Tamar and Li, Zhiheng and Hassner, Tal},    
    booktitle= {Proceedings of the IEEE/CVF European Conference on Computer Vision (ECCV) Workshops},
    year={2022},
    html={https://arxiv.org/abs/2212.06254},
    arxiv={arXiv:2212.06254},
    slides={RCV_ECCV_2022_slides.pdf}
}


@inproceedings{mehta2022information,
  abbr={UNSURE},
  bibtex_show={true},
  title={Information gain sampling for active learning in medical image classification},
  author={Mehta, Raghav and Shui, Changjian and Nichyporuk, Brennan and Arbel, Tal},
  booktitle={International Workshop on Uncertainty for Safe Utilization of Machine Learning in Medical Imaging (UNSURE)},
  pages={135--145},
  year={2022},
  organization={Springer},
  html={https://link.springer.com/chapter/10.1007/978-3-031-16749-2_13},
  arxiv={arXiv.org:2208.00974},
  doi={https://doi.org/10.1007/978-3-031-16749-2_13},
  poster={UNSURE_poster_2022.pdf},
  slides={UNSURE_2022_spotlight.pdf}
}


@inproceedings{nichyporuk2021cohort,
  abbr={DART},
  bibtex_show={true},
  title={Cohort bias adaptation in aggregated datasets for lesion segmentation},
  author={Nichyporuk, Brennan and Cardinell, Jillian and Szeto, Justin and Mehta, Raghav and Tsaftaris, Sotirios and Arnold, Douglas L and Arbel, Tal},
  booktitle={International Workshop on Domain Adaptation and Representation Transfer (DART)},
  pages={101--111},
  year={2021},
  organization={Springer},
  html={https://link.springer.com/chapter/10.1007/978-3-030-87722-4_10},
  arxiv={arXiv:2108.00713},
  doi={https://doi.org/10.1007/978-3-030-87722-4_10},
  slides={DART_2021.pdf}
}


@inproceedings{mehta2019propagating,
  abbr={UNSURE},
  bibtex_show={true},
  title={Propagating uncertainty across cascaded medical imaging tasks for improved deep learning inference},
  author={Mehta, Raghav and Christinck, Thomas and Nair, Tanya and Lemaitre, Paul and Arnold, Douglas and Arbel, Tal},
  booktitle={International Workshop on Uncertainty for Safe Utilization of Machine Learning in Medical Imaging (UNSURE))},
  pages={23--32},
  year={2019},
  organization={Springer},
  html={https://link.springer.com/chapter/10.1007/978-3-030-32689-0_3},
  doi={https://doi.org/10.1007/978-3-030-32689-0_3},
  slides={UNSURE_2019.pdf},
  poster={UNSURE_poster_final.pdf}
}


@inproceedings{kaur2019improving,
  abbr={DART},
  bibtex_show={true},
  title={Improving pathological structure segmentation via transfer learning across diseases},
  author={Kaur, Barleen and Lema{\^\i}tre, Paul and Mehta, Raghav and Sepahvand, Nazanin Mohammadi and Precup, Doina and Arnold, Douglas and Arbel, Tal},
  booktitle={International Workshop on Domain Adaptation and Representation Transfer (DART)},
  pages={90--98},
  year={2019},
  organization={Springer},
  html={https://link.springer.com/chapter/10.1007/978-3-030-33391-1_11},
  doi={https://doi.org/10.1007/978-3-030-33391-1_11},
  slides={DART_MICCAI.pdf},
  poster={DART_poster.pdf}
}


@inproceedings{mehta2018rs,
  abbr={SASHIMI},
  bibtex_show={true},
  title={RS-Net: Regression-segmentation 3D CNN for synthesis of full resolution missing brain MRI in the presence of tumours},
  author={Mehta, Raghav and Arbel, Tal},
  booktitle={Third International Workshop on Simulation and Synthesis in Medical Imaging (SASHIMI)},
  pages={119--129},
  year={2018},
  organization={Springer},
  html={https://link.springer.com/chapter/10.1007/978-3-030-00536-8_13},
  doi={https://doi.org/10.1007/978-3-030-00536-8_13},
  slides={SASHIMI-2018-presentation.pdf},
  arxiv={arXiv:1807.10972},
  extendedreport={RSNet_extension.pdf}
}

@inproceedings{majumdar2018learn,
  abbr={DLF},
  bibtex_show={true},
  title={To learn or not to learn features for deformable registration?},
  author={Majumdar, Aabhas and Mehta, Raghav and Sivaswamy, Jayanthi},
  booktitle={First International Workshop on Deep Learning Fails (DLF)},
  pages={52--60},
  year={2018},
  organization={Springer},
  html={https://link.springer.com/chapter/10.1007/978-3-030-02628-8_6},
  doi={https://doi.org/10.1007/978-3-030-02628-8_6},
  arxiv={arXiv:1709.01057},
  slides={DLF-2018_ToLearnOrNot.pdf}
}

@inproceedings{mehta20193d,
  abbr={BraTS-C},
  bibtex_show={true},
  title={3D U-Net for brain tumour segmentation},
  author={Mehta, Raghav and Arbel, Tal},
  booktitle={4th International Workshop on Brainlesion: Glioma, Multiple Sclerosis, Stroke and Traumatic Brain Injuries (BrainLes)},
  pages={254--266},
  year={2019},
  organization={Springer},
  html={https://link.springer.com/chapter/10.1007/978-3-030-11726-9_23},
  doi={https://doi.org/10.1007/978-3-030-11726-9_23},
  poster={BraTS_2018_poster_v2.pdf}
}

@article{sivaswamy2021sub,
  abbr={PrePrint},
  bibtex_show={true},
  title={Sub-cortical structure segmentation database for young population},
  author={Sivaswamy, Jayanthi and Thottupattu, Alphin J and Mehta, Raghav and Sheelakumari, R and Kesavadas, Chandrasekharan and others},
  journal={arXiv preprint},
  arxiv={arXiv:2111.01561},
  year={2021}
}

@ARTICLE{bakas2018identifying,
  abbr={PrePrint},
  bibtex_show={true},
  title={Identifying the best machine learning algorithms for brain tumor segmentation, progression assessment, and overall survival prediction in the {BRATS} challenge},
  author={Bakas, Spyridon and Reyes, Mauricio and Jakab, Andras and Bauer, Stefan and Rempfler, Markus and Crimi, Alessandro and Shinohara, Russell Takeshi and Berger, Christoph and Ha, Sung Min and Rozycki, Martin and Prastawa, Marcel and Alberts, Esther and Lipkova, Jana and Freymann, John and Kirby, Justin and Bilello, Michel and Fathallah-Shaykh, Hassan and Wiest, Roland and Kirschke, Jan and Wiestler, Benedikt and Colen, Rivka and Kotrotsou, Aikaterini and Lamontagne, Pamela and Marcus, Daniel and Milchenko, Mikhail and Nazeri, Arash and Weber, Marc-Andre and Mahajan, Abhishek and Baid, Ujjwal and Gerstner, Elizabeth and Kwon, Dongjin and Acharya, Gagan and Agarwal, Manu and Alam, Mahbubul and Albiol, Alberto and Albiol, Antonio and Albiol, Francisco J and Alex, Varghese and Allinson, Nigel and Amorim, Pedro H A and Amrutkar, Abhijit and Anand, Ganesh and Andermatt, Simon and Arbel, Tal and Arbelaez, Pablo and Avery, Aaron and Azmat, Muneeza and B., Pranjal and Bai, W and Banerjee, Subhashis and Barth, Bill and Batchelder, Thomas and Batmanghelich, Kayhan and Battistella, Enzo and Beers, Andrew and Belyaev, Mikhail and Bendszus, Martin and Benson, Eze and Bernal, Jose and Bharath, Halandur Nagaraja and Biros, George and Bisdas, Sotirios and Brown, James and Cabezas, Mariano and Cao, Shilei and Cardoso, Jorge M and Carver, Eric N and Casamitjana, Adri{\`a} and Castillo, Laura Silvana and Cat{\`a}, Marcel and Cattin, Philippe and Cerigues, Albert and Chagas, Vinicius S and Chandra, Siddhartha and Chang, Yi-Ju and Chang, Shiyu and Chang, Ken and Chazalon, Joseph and Chen, Shengcong and Chen, Wei and Chen, Jefferson W and Chen, Zhaolin and Cheng, Kun and Choudhury, Ahana Roy and Chylla, Roger and Cl{\'e}rigues, Albert and Colleman, Steven and Colmeiro, Ramiro German Rodriguez and Combalia, Marc and Costa, Anthony and Cui, Xiaomeng and Dai, Zhenzhen and Dai, Lutao and Daza, Laura Alexandra and Deutsch, Eric and Ding, Changxing and Dong, Chao and Dong, Shidu and Dudzik, Wojciech and Eaton-Rosen, Zach and Egan, Gary and Escudero, Guilherme and Estienne, Th{\'e}o and Everson, Richard and Fabrizio, Jonathan and Fan, Yong and Fang, Longwei and Feng, Xue and Ferrante, Enzo and Fidon, Lucas and Fischer, Martin and French, Andrew P and Fridman, Naomi and Fu, Huan and Fuentes, David and Gao, Yaozong and Gates, Evan and Gering, David and Gholami, Amir and Gierke, Willi and Glocker, Ben and Gong, Mingming and Gonz{\'a}lez-Vill{\'a}, Sandra and Grosges, T and Guan, Yuanfang and Guo, Sheng and Gupta, Sudeep and Han, Woo-Sup and Han, Il Song and Harmuth, Konstantin and He, Huiguang and Hern{\'a}ndez-Sabat{\'e}, Aura and Herrmann, Evelyn and Himthani, Naveen and Hsu, Winston and Hsu, Cheyu and Hu, Xiaojun and Hu, Xiaobin and Hu, Yan and Hu, Yifan and Hua, Rui and Huang, Teng-Yi and Huang, Weilin and Van Huffel, Sabine and Huo, Quan and Hv, Vivek and Iftekharuddin, Khan M and Isensee, Fabian and Islam, Mobarakol and Jackson, Aaron S and Jambawalikar, Sachin R and Jesson, Andrew and Jian, Weijian and Jin, Peter and Jose, V Jeya Maria and Jungo, Alain and Kainz, B and Kamnitsas, Konstantinos and Kao, Po-Yu and Karnawat, Ayush and Kellermeier, Thomas and Kermi, Adel and Keutzer, Kurt and Khadir, Mohamed Tarek and Khened, Mahendra and Kickingereder, Philipp and Kim, Geena and King, Nik and Knapp, Haley and Knecht, Urspeter and Kohli, Lisa and Kong, Deren and Kong, Xiangmao and Koppers, Simon and Kori, Avinash and Krishnamurthi, Ganapathy and Krivov, Egor and Kumar, Piyush and Kushibar, Kaisar and Lachinov, Dmitrii and Lambrou, Tryphon and Lee, Joon and Lee, Chengen and Lee, Yuehchou and Lee, M and Lefkovits, Szidonia and Lefkovits, Laszlo and Levitt, James and Li, Tengfei and Li, Hongwei and Li, Wenqi and Li, Hongyang and Li, Xiaochuan and Li, Yuexiang and Li, Heng and Li, Zhenye and Li, Xiaoyu and Li, Zeju and Li, Xiaogang and Li, Wenqi and Lin, Zheng-Shen and Lin, Fengming and Lio, Pietro and Liu, Chang and Liu, Boqiang and Liu, Xiang and Liu, Mingyuan and Liu, Ju and Liu, Luyan and Llado, Xavier and Lopez, Marc Moreno and Lorenzo, Pablo Ribalta and Lu, Zhentai and Luo, Lin and Luo, Zhigang and Ma, Jun and Ma, Kai and Mackie, Thomas and Madabushi, Anant and Mahmoudi, Issam and Maier-Hein, Klaus H and Maji, Pradipta and Mammen, C P and Mang, Andreas and Manjunath, B S and Marcinkiewicz, Michal and McDonagh, S and McKenna, Stephen and McKinley, Richard and Mehl, Miriam and Mehta, Sachin and Mehta, Raghav and Meier, Raphael and Meinel, Christoph and Merhof, Dorit and Meyer, Craig and Miller, Robert and Mitra, Sushmita and Moiyadi, Aliasgar and Molina-Garcia, David and Monteiro, Miguel A B and Mrukwa, Grzegorz and Myronenko, Andriy and Nalepa, Jakub and Ngo, Thuyen and Nie, Dong and Ning, Holly and Niu, Chen and Nuechterlein, Nicholas K and Oermann, Eric and Oliveira, Arlindo and Oliveira, Diego D C and Oliver, Arnau and Osman, Alexander F I and Ou, Yu-Nian and Ourselin, Sebastien and Paragios, Nikos and Park, Moo Sung and Paschke, Brad and Pauloski, J Gregory and Pawar, Kamlesh and Pawlowski, Nick and Pei, Linmin and Peng, Suting and Pereira, Silvio M and Perez-Beteta, Julian and Perez-Garcia, Victor M and Pezold, Simon and Pham, Bao and Phophalia, Ashish and Piella, Gemma and Pillai, G N and Piraud, Marie and Pisov, Maxim and Popli, Anmol and Pound, Michael P and Pourreza, Reza and Prasanna, Prateek and Prkovska, Vesna and Pridmore, Tony P and Puch, Santi and Puybareau, {\'E}lodie and Qian, Buyue and Qiao, Xu and Rajchl, Martin and Rane, Swapnil and Rebsamen, Michael and Ren, Hongliang and Ren, Xuhua and Revanuru, Karthik and Rezaei, Mina and Rippel, Oliver and Rivera, Luis Carlos and Robert, Charlotte and Rosen, Bruce and Rueckert, Daniel and Safwan, Mohammed and Salem, Mostafa and Salvi, Joaquim and Sanchez, Irina and S{\'a}nchez, Irina and Santos, Heitor M and Sartor, Emmett and Schellingerhout, Dawid and Scheufele, Klaudius and Scott, Matthew R and Scussel, Artur A and Sedlar, Sara and Serrano-Rubio, Juan Pablo and Shah, N Jon and Shah, Nameetha and Shaikh, Mazhar and Shankar, B Uma and Shboul, Zeina and Shen, Haipeng and Shen, Dinggang and Shen, Linlin and Shen, Haocheng and Shenoy, Varun and Shi, Feng and Shin, Hyung Eun and Shu, Hai and Sima, Diana and Sinclair, M and Smedby, Orjan and Snyder, James M and Soltaninejad, Mohammadreza and Song, Guidong and Soni, Mehul and Stawiaski, Jean and Subramanian, Shashank and Sun, Li and Sun, Roger and Sun, Jiawei and Sun, Kay and Sun, Yu and Sun, Guoxia and Sun, Shuang and Suter, Yannick R and Szilagyi, Laszlo and Talbar, Sanjay and Tao, Dacheng and Tao, Dacheng and Teng, Zhongzhao and Thakur, Siddhesh and Thakur, Meenakshi H and Tharakan, Sameer and Tiwari, Pallavi and Tochon, Guillaume and Tran, Tuan and Tsai, Yuhsiang M and Tseng, Kuan-Lun and Tuan, Tran Anh and Turlapov, Vadim and Tustison, Nicholas and Vakalopoulou, Maria and Valverde, Sergi and Vanguri, Rami and Vasiliev, Evgeny and Ventura, Jonathan and Vera, Luis and Vercauteren, Tom and Verrastro, C A and Vidyaratne, Lasitha and Vilaplana, Veronica and Vivekanandan, Ajeet and Wang, Guotai and Wang, Qian and Wang, Chiatse J and Wang, Weichung and Wang, Duo and Wang, Ruixuan and Wang, Yuanyuan and Wang, Chunliang and Wang, Guotai and Wen, Ning and Wen, Xin and Weninger, Leon and Wick, Wolfgang and Wu, Shaocheng and Wu, Qiang and Wu, Yihong and Xia, Yong and Xu, Yanwu and Xu, Xiaowen and Xu, Peiyuan and Yang, Tsai-Ling and Yang, Xiaoping and Yang, Hao-Yu and Yang, Junlin and Yang, Haojin and Yang, Guang and Yao, Hongdou and Ye, Xujiong and Yin, Changchang and Young-Moxon, Brett and Yu, Jinhua and Yue, Xiangyu and Zhang, Songtao and Zhang, Angela and Zhang, Kun and Zhang, Xuejie and Zhang, Lichi and Zhang, Xiaoyue and Zhang, Yazhuo and Zhang, Lei and Zhang, Jianguo and Zhang, Xiang and Zhang, Tianhao and Zhao, Sicheng and Zhao, Yu and Zhao, Xiaomei and Zhao, Liang and Zheng, Yefeng and Zhong, Liming and Zhou, Chenhong and Zhou, Xiaobing and Zhou, Fan and Zhu, Hongtu and Zhu, Jin and Zhuge, Ying and Zong, Weiwei and Kalpathy-Cramer, Jayashree and Farahani, Keyvan and Davatzikos, Christos and van Leemput, Koen and Menze, Bjoern},
  abstract={Gliomas are the most common primary brain malignancies, with different degrees of aggressiveness, variable prognosis and various heterogeneous histologic sub-regions, i.e., peritumoral edematous/invaded tissue, necrotic core, active and non-enhancing core. This intrinsic heterogeneity is also portrayed in their radio-phenotype, as their sub-regions are depicted by varying intensity profiles disseminated across multi-parametric magnetic resonance imaging (mpMRI) scans, reflecting varying biological properties. Their heterogeneous shape, extent, and location are some of the factors that make these tumors difficult to resect, and in some cases inoperable. The amount of resected tumor is a factor also considered in longitudinal scans, when evaluating the apparent tumor for potential diagnosis of progression. Furthermore, there is mounting evidence that accurate segmentation of the various tumor sub-regions can offer the basis for quantitative image analysis towards prediction of patient overall survival. This study assesses the state-of-the-art machine learning (ML) methods used for brain tumor image analysis in mpMRI scans, during the last seven instances of the International Brain Tumor Segmentation (BraTS) challenge, i.e., 2012-2018. Specifically, we focus on i) evaluating segmentations of the various glioma sub-regions in pre-operative mpMRI scans, ii) assessing potential tumor progression by virtue of longitudinal growth of tumor sub-regions, beyond use of the RECIST/RANO criteria, and iii) predicting the overall survival from pre-operative mpMRI scans of patients that underwent gross total resection. Finally, we investigate the challenge of identifying the best ML algorithms for each of these tasks, considering that apart from being diverse on each instance of the challenge, the multi-institutional mpMRI BraTS dataset has also been a continuously evolving/growing dataset. t has also been a continuously evolving/growing dataset.},
  journal={arXiv preprint},
  arxiv={arXiv:1811.02629},
  year={2018}
}

@phdthesis{mcgillthesis,
  abbr={Thesis},
  bibtex_show={true},
  title={Integrating Bayesian Deep Learning Uncertainties in Medical Image Analysis},
  abstract={Although Deep Learning (DL) models have been shown to perform very well on various medical imaging tasks, inference in the presence of pathology presents several challenges to common models. These challenges impede the integration of DL models into real clinical workflows. Deployment of these models into real clinical contexts requires: (1) that the confidence in DL model predictions be accurately expressed in the form of uncertainties and (2) that they exhibit robustness and fairness across different sub-populations. Quantifying the reliability of DL model predictions in the form of uncertainties could enable clinical review of the most uncertain regions, thereby building trust and paving the way toward clinical translation. Similarly, by embedding uncertainty estimates across cascaded inference tasks, prevalent in medical image analysis, performance on the downstream inference tasks should also be improved. In this thesis, we develop an uncertainty quantification score for the task of Brain Tumour Segmentation. We evaluate the score's usefulness during the two consecutive Brain Tumour Segmentation (BraTS) challenges, BraTS 2019 and BraTS 2020. Overall, our findings confirm the importance and complementary value that uncertainty estimates provide to segmentation algorithms, highlighting the need for uncertainty quantification in medical image analyses. We further show the importance of uncertainty estimates in medical image analysis by propagating uncertainty generated by upstream tasks into the downstream task of interest. Our results on three different clinically relevant tasks indicate that uncertainty propagation helps improve the performance of the downstream task of interest. Additionally, we combine the aspect of uncertainty estimates with fairness across demographic subgroups into the picture. By performing extensive experiments on multiple tasks, we show that popular ML methods for achieving fairness across different subgroups, such as data-balancing and distributionally robust optimization, succeed in terms of the model performances for some of the tasks. However, this can come at the cost of poor uncertainty estimates associated with the model predictions. This tradeoff must be mitigated if fairness models are to be adopted in medical image analysis. In the last part of the thesis, we look at Active Learning (AL) for reduced manual labeling of a dataset. Specifically, we present an information-theoretic active learning framework that guides the optimal selection of images for labeling. Results indicate that the proposed framework outperforms several existing AL methods, and by careful design choices, it can be integrated into existing deep learning classifiers with minimal computational overhead},
  author={Mehta, Raghav},
  year=2023,
  address={Montreal, Canada},
  school={McGill University},
  type={PhD thesis},
  html={https://escholarship.mcgill.ca/concern/theses/9p290g949},
  slides={Raghav_Mehta_PhD_Defense_presentation.pdf}
}

@phdthesis{iiitthesis,
  abbr={Thesis},
  bibtex_show={true},
  title={Population specific template construction and brain structure segmentation using deep learning methods},
  abstract={A brain template, such as MNI152 is a digital (magentic resonance image or MRI) representation of the brain in a reference coordinate system for the neuroscience research. Structural atlases, such as AAL and DKA, delineate the brain into cortical and subcortical structures which are used in Voxel Based Morphometry (VBM) and fMRI analysis. Many population specific templates, i.e. Chinese, Korean, etc., have been constructed recently. It was observed that there are morphological differences between the average brain of the eastern and the western population. In this thesis, we report on the development of a population specific brain template for the young Indian population. This is derived from a multi-centeric MRI dataset of 100 Indian adults (21 - 30 years old). Measurements made with this template indicated that the Indian brain, on average, is smaller in height and width compared to the Caucasian and the Chinese brain. A second problem this thesis examines is automated segmentation of cortical and non-cortical human brain structures, using multiple structural atlases. This has been hitherto approached using computationally expensive non-rigid registration followed by label fusion. We propose an alternative approach for this using a Convolutional Neural Network (CNN) which classifies a voxel into one of many structures. Evaluation of the proposed method on various datasets showed that the mean Dice coefficient varied from 0.844±0.031 to 0.743±0.019 for datasets with the least (32) and the most (134) number of labels, respectively. These figures are marginally better or on par with those obtained with the current state of the art methods on nearly all datasets, at a reduced computational time. We also propose an end-to-end trainable Fully Convolutional Neural Network (FCNN) architecture called the M-net, for segmenting deep (human) brain structures. A novel scheme is used to learn to combine and represent 3D context information of a given slice in a 2D slice. Consequently, the M-net utilizes only 2D convolution though it operates on 3D data. Experiment results show that the M-net outperforms other state-of-the-art model-based segmentation methods in terms of dice coefficient and is at least 3 times faster than them.},
  author={Mehta, Raghav},
  year=2017,
  address={Hyderabad, India},
  school={International Institute of Information Technology -  Hyderabad (IIIT-H)},
  type={MS thesis},
  html={https://web2py.iiit.ac.in/research_centres/publications/view_publication/mastersthesis/511},
  slides={MS_thesis_presentation.pdf}
}
